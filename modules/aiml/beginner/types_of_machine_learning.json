{
    "module_header": {
        "module_title": "Types of Machine Learning",
        "subject": "Artificial Intelligence & Machine Learning",
        "level": "Beginner",
        "prerequisites": [
            "Introduction to Machine Learning",
            "Basic probability and statistics"
        ],
        "learning_outcomes": [
            "Understand supervised learning in depth: classification and regression",
            "Identify supervised learning algorithms and their use cases",
            "Understand unsupervised learning: clustering, dimensionality reduction, association",
            "Apply clustering algorithms (K-means, hierarchical) to real problems",
            "Understand reinforcement learning: agents, rewards, policies",
            "Distinguish between on-policy and off-policy RL methods",
            "Recognize semi-supervised and transfer learning approaches"
        ]
    },
    "definition": "Machine Learning divides into types based on learning paradigm. **Supervised Learning**: Learns from labeled data (input-output pairs); predicts outputs for new inputs. Subtypes: Classification (categorical output—spam detection, image recognition), Regression (continuous output—price prediction, forecasting). Algorithms: Linear/Logistic Regression, Decision Trees, SVM, Neural Networks. **Unsupervised Learning**: Finds patterns in unlabeled data. Subtypes: Clustering (group similar items—K-means, hierarchical), Dimensionality reduction (compress data—PCA), Association (find rules—market basket). **Reinforcement Learning**: Agent learns optimal actions through trial-and-error, receiving rewards. Components: Agent, Environment, State, Action, Reward, Policy. Algorithms: Q-learning, SARSA, Policy Gradients. **Others**: Semi-supervised (few labels + many unlabeled), Transfer learning (reuse pre-trained models).",
    "concept_overview": [
        "Supervised: Labeled training (x,y) pairs. Learn f: X→Y. Classification (categories) vs Regression (numbers).",
        "Classification examples: Spam detection, disease diagnosis, image recognition (categorical output).",
        "Regression examples: House price, stock prediction, temperature forecasting (continuous output).",
        "Unsupervised: No labels. Find structure. Clustering (groups), PCA (reduce dimensions), association rules.",
        "Clustering: K-means (partition into k clusters), Hierarchical (tree of clusters), DBSCAN (density-based).",
        "Reinforcement: Agent-environment interaction. Agent takes actions, receives rewards, learns optimal policy.",
        "Semi-supervised: Small labeled + large unlabeled data. Transfer: Reuse knowledge from related task."
    ],
    "theory": [
        "Understanding ML types enables matching problems to appropriate learning paradigms. Supervised learning dominates practical applications where labeled data available: historical data with known outcomes trains models predicting future outcomes. The supervision (correct answers during training) guides learning toward accurate predictions. Classification vs regression distinction critical—determines algorithm choice and evaluation metrics. Classification for discrete decisions (approve/deny loan, diagnose disease), regression for forecasting continuous quantities (sales, demand, prices). Supervised learning challenges: acquiring labels (expensive—requires expert annotation), class imbalance (rare events like fraud underrepresented), overfitting (especially with limited data). Popular algorithms span simple (linear regression—assumes linear relationship) to complex (neural networks—learn nonlinear patterns). Model selection balances interpretability (linear models transparent), performance (deep learning powerful but opaque), and data requirements (deep learning needs large datasets).",
        "The fundamental supervised learning approaches solve different prediction tasks. **Classification**: Predict discrete class labels. Binary (2 classes—spam/not spam) vs Multi-class (many classes—digit 0-9). Algorithms: Logistic Regression (probability-based, linear decision boundary), Decision Trees (hierarchical if-then rules), Random Forests (ensemble of trees—reduce overfitting), SVM (maximum margin classification), K-NN (classify by nearest neighbors), Neural Networks (learn complex non-linear boundaries). Evaluation: accuracy, precision, recall, F1-score, ROC-AUC. Applications: email filtering, sentiment analysis, medical diagnosis, fraud detection. **Regression**: Predict continuous values. Linear Regression (y = wx + b—assumes linear relationship), Polynomial Regression (non-linear curves), Ridge/Lasso (regularized to prevent overfitting), Decision Tree Regression (piecewise constant predictions), Neural Networks (universal function approximators). Evaluation: MSE (mean squared error), RMSE, MAE, R². Applications: price prediction, demand forecasting, risk assessment. **Unsupervised learning**: No labels—algorithm discovers structure autonomously. **Clustering**: Partition data into groups where intra-cluster similarity high, inter-cluster similarity low. K-means (specify k clusters, minimize within-cluster variance—fast, but k must be chosen, sensitive to initialization), Hierarchical (builds tree—no need to specify k, visualized as dendrogram), DBSCAN (density-based—finds arbitrary-shaped clusters, identifies outliers). Applications: customer segmentation, document organization, image compression, anomaly detection. **Dimensionality Reduction**: Project high-dimensional data to lower dimensions preserving structure. PCA (principal component analysis—linear projection maximizing variance), t-SNE (non-linear for visualization). Applications: visualization (3D from 100D), noise reduction, feature extraction, data compression. **Association Rule Mining**: Discover interesting relationships in data. Example: market basket analysis (customers who buy bread also buy milk). Apriori algorithm finds frequent itemsets. **Reinforcement Learning (RL)**: Agent learns through interaction. Components: Agent (learner/decision-maker), Environment (world agent interacts with), State (current situation), Action (what agent can do), Reward (feedback from environment), Policy (strategy mapping states to actions). Goal: Learn optimal policy maximizing cumulative reward. Algorithms: Q-learning (learn action-value function Q(s,a)—expected reward for action a in state s), SARSA (on-policy TD learning), Policy Gradients (directly optimize policy), Actor-Critic (combines value and policy), Deep RL (use neural networks—AlphaGo, Atari games). Applications: game playing, robotics, autonomous driving, resource allocation, recommendation systems.",
        "Mastery of ML types is critically important for selecting appropriate approaches to real problems. Supervised learning when labeled data plentiful and task is prediction (most business applications—credit scoring, churn prediction, quality control). Unsupervised when exploring data without predefined targets (market segmentation, anomaly detection, data understanding). Reinforcement when sequential decision-making with delayed rewards (robotics, game AI, control systems). Trade-offs: Supervised requires expensive labels but achieves high accuracy for prediction; Unsupervised requires no labels but less concrete evaluation (clustering quality subjective); RL handles sequential decisions but sample-inefficient (requires many interactions). Hybrid approaches: Semi-supervised leverages small labeled set with large unlabeled data (reduces labeling cost—important for medical imaging, NLP). Transfer learning reuses models trained on large datasets (ImageNet) fine-tuning for specific tasks (medical images)—dramatically reduces data/compute requirements. Active learning: algorithm selects informative examples for labeling (minimizes labeling effort). Modern trends: Self-supervised learning (create labels from data itself—predict next word in text, image rotation), Meta-learning (learning to learn—few-shot adaptation), Multi-task learning (train single model on multiple related tasks—shared representations). Challenges: Choosing right type based on problem structure and data availability, balancing performance vs interpretability vs computational cost, handling real-world data issues (noise, imbalance, distribution shift). In examinations, demonstrating ability to classify problems into ML types, select appropriate algorithms, understand trade-offs, and apply to real scenarios shows comprehensive ML understanding essential for practical AI applications."
    ],
    "mathematical_formulation": [
        {
            "formula": "Supervised: Minimize $\\mathcal{L} = \\frac{1}{n}\\sum_{i=1}^{n} L(f(x_i), y_i)$",
            "explanation": "Learn function f minimizing average loss between predictions f(x) and true labels y over training data."
        },
        {
            "formula": "Classification: $P(y|x) = \\sigma(w^Tx + b)$ (logistic regression)",
            "explanation": "Predict probability of class y given input x using sigmoid σ transforming linear combination."
        },
        {
            "formula": "Regression: $\\hat{y} = w^Tx + b$ (linear regression)",
            "explanation": "Predict continuous value as weighted sum of features plus bias."
        },
        {
            "formula": "K-means: Minimize $\\sum_{i=1}^{k}\\sum_{x \\in C_i} ||x - \\mu_i||^2$",
            "explanation": "Find k cluster centers μ minimizing sum of squared distances from points to their assigned centers."
        },
        {
            "formula": "RL: $\\pi^* = \\arg\\max_{\\pi} \\mathbb{E}[\\sum_{t} \\gamma^t r_t | \\pi]$",
            "explanation": "Optimal policy π* maximizes expected cumulative discounted rewards γ^t r_t."
        }
    ],
    "worked_examples": [
        {
            "difficulty": "Basic",
            "problem": "Classify ML problems and select appropriate algorithms.",
            "solution_steps": [
                "**Problem 1: Email spam detection**",
                "- **Type:** Supervised Learning - Classification (binary)",
                "- **Input:** Email text features (words, sender, etc.)",
                "- **Output:** Spam or Not Spam (categorical)",
                "- **Algorithms:** Naive Bayes, Logistic Regression, SVM",
                "",
                "**Problem 2: House price prediction**",
                "- **Type:** Supervised Learning - Regression",
                "- **Input:** House features (size, location, bedrooms)",
                "- **Output:** Price (continuous number)",
                "- **Algorithms:** Linear Regression, Random Forest Regressor",
                "",
                "**Problem 3: Customer segmentation for marketing**",
                "- **Type:** Unsupervised Learning - Clustering",
                "- **Input:** Customer purchase history, demographics (no labels)",
                "- **Output:** Customer groups/segments",
                "- **Algorithms:** K-means, Hierarchical Clustering",
                "",
                "**Problem 4: Teaching robot to walk**",
                "- **Type:** Reinforcement Learning",
                "- **Setup:** Robot (agent) tries movements (actions), receives reward for forward progress",
                "- **Goal:** Learn walking policy maximizing distance",
                "- **Algorithms:** Q-learning, Policy Gradients, PPO",
                "",
                "**Problem 5: Handwritten digit recognition (0-9)**",
                "- **Type:** Supervised Learning - Multi-class Classification",
                "- **Input:** Image pixels",
                "- **Output:** Digit class (0, 1, 2, ..., 9)",
                "- **Algorithms:** Neural Networks (CNN), SVM, k-NN"
            ],
            "final_answer": "Match problem structure to ML type: Labeled data→Supervised (Classification=categorical, Regression=continuous). No labels→Unsupervised (Clustering). Sequential decision-making→Reinforcement."
        },
        {
            "difficulty": "Intermediate",
            "problem": "Explain K-means clustering algorithm and when to use it.",
            "solution_steps": [
                "**K-means Clustering Algorithm:**",
                "",
                "**Goal:** Partition n data points into k clusters minimizing within-cluster variance.",
                "",
                "**Steps:**",
                "1. **Initialize:** Randomly select k points as initial cluster centers (centroids)",
                "2. **Assignment:** Assign each point to nearest centroid (Euclidean distance)",
                "3. **Update:** Recalculate centroids as mean of points in each cluster",
                "4. **Repeat:** Steps 2-3 until convergence (centroids don't change)",
                "",
                "**Example:**",
                "- Data: 100 customers with purchase amounts [feature1, feature2]",
                "- k=3 (want 3 segments: low, medium, high spenders)",
                "- Initialize 3 random centroids",
                "- Iterate: assign customers to nearest centroid, update centroids",
                "- Converges: stable 3 clusters",
                "",
                "**When to Use K-means:**",
                "✅ **Good for:**",
                "- Spherical/globular clusters",
                "- Known or estimate k (number of clusters)",
                "- Fast clustering needed (efficient: O(nkt) where t=iterations)",
                "- Continuous numerical features",
                "",
                "❌ **NOT good for:**",
                "- Arbitrary cluster shapes (K-means assumes spherical)",
                "- Different cluster sizes/densities",
                "- Unknown k (must specify beforehand—use Elbow method/Silhouette)",
                "- Outliers (sensitive—pull centroids)",
                "",
                "**Applications:**",
                "- Customer segmentation (group similar customers)",
                "- Image compression (reduce colors)",
                "- Document clustering (topic grouping)",
                "- Anomaly detection preprocessing",
                "",
                "**Limitations:**",
                "- Must choose k (hyperparameter)",
                "- Sensitive to initialization (run multiple times, choose best)",
                "- Assumes convex clusters (use DBSCAN for arbitrary shapes)"
            ],
            "final_answer": "K-means: Iterative clustering (assign→update centroids→repeat). Fast, good for spherical clusters. Must choose k. Use for customer segmentation, compression. Avoid for arbitrary shapes."
        }
    ],
    "logical_derivation": "ML types reflect different learning scenarios: Supervised has ground truth labels enabling learning input-output mapping f: X→Y optimized via loss minimization. Output type determines classification (discrete) vs regression (continuous). Unsupervised lacks labels—algorithms find structure by optimizing internal criteria (K-means minimizes within-cluster variance, PCA maximizes variance captured). Reinforcement learns through interaction: agent explores state space, receives scalar rewards, learns policy maximizing cumulative discounted reward (balances immediate vs future gains). Each type suits different problem structures: labels available + prediction task → supervised; pattern discovery → unsupervised; sequential decision-making with feedback → reinforcement. Algorithmic diversity within each type reflects different assumptions (linear vs non-linear, parametric vs non-parametric, deterministic vs probabilistic).",
    "applications": [
        "**Supervised Classification:** Spam filtering, disease diagnosis, fraud detection, image recognition, sentiment analysis.",
        "**Supervised Regression:** Stock price forecasting, demand prediction, weather forecasting, real estate valuation.",
        "**Unsupervised Clustering:** Customer segmentation, document organization, gene expression analysis, image compression.",
        "**Dimensionality Reduction:** Data visualization (t-SNE for high-D data), feature extraction, noise reduction.",
        "**Reinforcement Learning:** Game playing (AlphaGo, Atari), robotics (manipulation, walking), autonomous driving, resource allocation.",
        "**Semi-supervised:** Medical image analysis (few labeled scans + many unlabeled), web page classification.",
        "**Transfer Learning:** Image classification (fine-tune ImageNet models), NLP (fine-tune BERT/GPT)."
    ],
    "key_takeaways": [
        "Supervised: Labeled (x,y) data. Classification (categorical)classificação vs Regression (continuous). Need labels.",
        "Classification: Predict category. Logistic Regression, Decision Trees, SVM, Neural Networks. Metrics: accuracy, precision, recall.",
        "Regression: Predict number. Linear Regression, Random Forest. Metrics: MSE, RMSE, MAE, R².",
        "Unsupervised: No labels. Clustering (K-means, hierarchical), PCA (dimensionality reduction), association rules.",
        "K-means: Partition into k clusters minimizing within-cluster variance. Fast, spherical clusters, must choose k.",
        "Reinforcement: Agent-environment, actions-rewards. Learn policy maximizing cumulative reward. Q-learning, policy gradients.",
        "Semi-supervised: Few labels + many unlabeled. Transfer: Reuse pre-trained models. Both reduce data requirements."
    ],
    "common_mistakes": [
        {
            "mistake": "Using classification algorithm for regression task",
            "why_it_occurs": "Students don't distinguish output types.",
            "how_to_avoid": "Check output: categorical→classification (logistic regression, SVM for classification). Continuous→regression (linear regression). Mixing causes errors."
        },
        {
            "mistake": "Applying K-means without choosing k properly",
            "why_it_occurs": "Students randomly pick k without analysis.",
            "how_to_avoid": "Use Elbow method (plot inertia vs k, look for elbow) or Silhouette score. K-means requires specifying k—crucial hyperparameter."
        },
        {
            "mistake": "Expecting unsupervised learning to give 'correct' answers",
            "why_it_occurs": "Students think clustering has ground truth.",
            "how_to_avoid": "Unsupervised finds patterns, no 'right' answer. Evaluation subjective (cluster coherence). Supervised has labels (objective evaluation)."
        },
        {
            "mistake": "Confusing semi-supervised with unsupervised",
            "why_it_occurs": "Misunderstanding partial labels.",
            "how_to_avoid": "Semi-supervised: SOME labels (small labeled + large unlabeled). Unsupervised: NO labels. Semi-supervised leverages both."
        },
        {
            "mistake": "Using wrong evaluation metrics",
            "why_it_occurs": "Students use classification metrics for regression.",
            "how_to_avoid": "Classification: accuracy, precision, recall, F1, AUC. Regression: MSE, RMSE, MAE, R². Match metric to task type."
        }
    ],
    "quiz": [
        {
            "question": "Which ML type requires labeled training data?",
            "options": [
                "Supervised Learning",
                "Unsupervised Learning",
                "Reinforcement Learning",
                "None"
            ],
            "correct_answer": 0,
            "explanation": "Supervised learning requires labeled (input, output) pairs for training. Unsupervised has no labels. RL uses rewards, not labels."
        },
        {
            "question": "Which is a classification task?",
            "options": [
                "Email spam detection (spam/not spam)",
                "House price prediction",
                "Temperature forecasting",
                "Stock price prediction"
            ],
            "correct_answer": 0,
            "explanation": "Classification: categorical output. Spam detection predicts category (spam/not spam). Others predict continuous values (regression)."
        },
        {
            "question": "Which is a regression task?",
            "options": [
                "Predicting house price",
                "Disease diagnosis (yes/no)",
                "Image classification (cat/dog)",
                "Spam filtering"
            ],
            "correct_answer": 0,
            "explanation": "Regression: continuous output. House price is number. Others are categorical (classification tasks)."
        },
        {
            "question": "What does K-means require as input?",
            "options": [
                "Number of clusters k",
                "Labels for each point",
                "Decision tree depth",
                "Learning rate"
            ],
            "correct_answer": 0,
            "explanation": "K-means clustering requires specifying k (number of clusters) beforehand. Must choose k using Elbow method or domain knowledge."
        },
        {
            "question": "Which is an unsupervised learning task?",
            "options": [
                "Customer segmentation (clustering)",
                "Email spam classification",
                "Stock price prediction",
                "Disease diagnosis"
            ],
            "correct_answer": 0,
            "explanation": "Customer segmentation: find groups in unlabeled data (clustering—unsupervised). Others have labels/targets (supervised)."
        },
        {
            "question": "What does reinforcement learning optimize?",
            "options": [
                "Cumulative reward over time",
                "Prediction accuracy",
                "Clustering quality",
                "Dimensionality"
            ],
            "correct_answer": 0,
            "explanation": "RL: agent learns policy maximizing cumulative discounted reward through trial-and-error interaction with environment."
        },
        {
            "question": "Which algorithm is used for dimensionality reduction?",
            "options": [
                "PCA (Principal Component Analysis)",
                "K-means",
                "Logistic Regression",
                "Q-learning"
            ],
            "correct_answer": 0,
            "explanation": "PCA projects high-dimensional data to lower dimensions preserving variance. Used for visualization, feature extraction, compression."
        },
        {
            "question": "What is semi-supervised learning?",
            "options": [
                "Uses small labeled + large unlabeled data",
                "Same as unsupervised",
                "Uses only labeled data",
                "Uses rewards instead of labels"
            ],
            "correct_answer": 0,
            "explanation": "Semi-supervised: leverages small labeled dataset with large unlabeled data. Combines supervised and unsupervised benefits. Reduces labeling cost."
        },
        {
            "question": "Which metric is appropriate for regression?",
            "options": [
                "Mean Squared Error (MSE)",
                "Accuracy",
                "Precision",
                "Recall"
            ],
            "correct_answer": 0,
            "explanation": "Regression metrics: MSE, RMSE, MAE, R² (continuous predictions). Classification metrics: accuracy, precision, recall (categorical predictions)."
        },
        {
            "question": "What is transfer learning?",
            "options": [
                "Reusing pre-trained model for new task",
                "Transferring data between datasets",
                "Same as unsupervised learning",
                "Training multiple models"
            ],
            "correct_answer": 0,
            "explanation": "Transfer learning: reuse model trained on large dataset (ImageNet, BERT), fine-tune for specific task. Reduces data/compute requirements dramatically."
        },
        {
            "question": "Which is a clustering algorithm?",
            "options": [
                "K-means",
                "Linear Regression",
                "Logistic Regression",
                "Q-learning"
            ],
            "correct_answer": 0,
            "explanation": "K-means: unsupervised clustering (partition data into k groups). Others: linear regression (supervised regression), logistic (classification), Q-learning (RL)."
        },
        {
            "question": "In RL, what is a policy?",
            "options": [
                "Strategy mapping states to actions",
                "Reward function",
                "Training dataset",
                "Cluster center"
            ],
            "correct_answer": 0,
            "explanation": "Policy π: agent's strategy mapping states to actions. Optimal policy π* maximizes expected cumulative reward. Core concept in RL."
        }
    ],
    "ai_summary": {
        "key_ideas": [
            "Supervised: Labeled data (x,y). Learn f: X→Y. Classification (categorical) vs Regression (continuous).",
            "Classification: Predict category (spam/not, disease yes/no). Algorithms: Logistic Regression, Trees, SVM, NN. Metrics: accuracy, precision, recall.",
            "Regression: Predict number (price, temperature). Algorithms: Linear Regression, Random Forest. Metrics: MSE, RMSE, MAE, R².",
            "Unsupervised: No labels. Find structure. Clustering (K-means, hierarchical), PCA (dimensionality reduction), association rules.",
            "K-means: Partition into k clusters minimizing within-cluster variance. Iterative (assign→update→repeat). Must choose k. Fast, spherical clusters.",
            "Hierarchical: Build tree of clusters (dendrogram). No need to specify k. Agglomerative (bottom-up) or divisive (top-down).",
            "PCA: Project high-D to low-D preserving variance. Linear transformation. Use: visualization, feature extraction, compression.",
            "Reinforcement Learning: Agent-environment interaction. Agent takes actions, receives rewards, learns optimal policy maximizing cumulative reward.",
            "RL components: State (situation), Action (what agent does), Reward (feedback), Policy (strategy), Value function (expected return).",
            "Semi-supervised: Few labels + many unlabeled. Transfer: Reuse pre-trained model. Both reduce data requirements significantly."
        ],
        "important_formulas": [
            "Supervised: Minimize average loss over (x,y) pairs",
            "Classification: P(y|x) = σ(w^T x + b)",
            "Regression: ŷ = w^T x + b",
            "K-means: Minimize Σ ||x - μ_i||²",
            "RL: Maximize E[Σ γ^t r_t]"
        ],
        "common_exam_traps": [
            "Classification vs Regression: Output type determines task. Categorical→classification, Continuous→regression. Don't mix algorithms.",
            "K-means requires choosing k beforehand. Use Elbow/Silhouette method. Sensitive to initialization.",
            "Unsupervised has no 'correct' answer (no labels). Evaluation subjective. Supervised has objective metrics.",
            "Semi-supervised ≠ Unsupervised. Semi has SOME labels. Unsupervised has NO labels.",
            "Metrics: Classification (accuracy, precision, recall, F1). Regression (MSE, RMSE, MAE). Match metric to task."
        ],
        "exam_tip": "Remember: Supervised=labels (Classification=category, Regression=number). Unsupervised=no labels (Clustering, PCA). RL=rewards. K-means needs k. Use appropriate metrics for each task type."
    }
}