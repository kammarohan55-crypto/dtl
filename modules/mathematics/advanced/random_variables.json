{
    "module_header": {
        "module_title": "Random Variables",
        "subject": "Mathematics",
        "level": "Advanced",
        "prerequisites": [
            "Probability basics and axioms",
            "Sample spaces and events",
            "Functions and their properties",
            "Summation and integration concepts"
        ],
        "learning_outcomes": [
            "Define random variables and distinguish between discrete and continuous types",
            "Understand and compute probability mass functions (PMF) and probability density functions (PDF)",
            "Calculate and interpret cumulative distribution functions (CDF)",
            "Compute expected values and apply linearity of expectation",
            "Calculate variance and standard deviation of random variables",
            "Apply functions of random variables and transformation techniques"
        ]
    },
    "definition": "A random variable is a function $X: S \\to \\mathbb{R}$ that assigns a numerical value to each outcome in a sample space $S$. A discrete random variable takes countable values with probabilities given by the probability mass function $p(x) = P(X = x)$. A continuous random variable takes uncountably many values with probability density function $f(x)$ where $P(a \\leq X \\leq b) = \\int_a^b f(x)\\,dx$. The cumulative distribution function is $F(x) = P(X \\leq x)$ for both types.",
    "concept_overview": [
        "Random variables transform outcomes of random experiments into numerical values, enabling mathematical analysis of uncertainty.",
        "Discrete random variables have PMF $p(x)$ satisfying $\\sum_x p(x) = 1$ and $p(x) \\geq 0$; examples include coin flips, die rolls, and counts.",
        "Continuous random variables have PDF $f(x)$ satisfying $\\int_{-\\infty}^{\\infty} f(x)\\,dx = 1$ and $f(x) \\geq 0$; examples include heights, temperatures, and lifetimes.",
        "The CDF $F(x) = P(X \\leq x)$ is non-decreasing, right-continuous, with $\\lim_{x \\to -\\infty} F(x) = 0$ and $\\lim_{x \\to \\infty} F(x) = 1$.",
        "Expected value $E[X] = \\sum x \\cdot p(x)$ (discrete) or $E[X] = \\int x \\cdot f(x)\\,dx$ (continuous) measures the center or average value."
    ],
    "theory": [
        "Random variables provide the mathematical bridge between probability theory and statistical analysis, enabling quantitative modeling of uncertain quantities in engineering and science. By mapping outcomes to numbers, random variables allow application of calculus and analysis to probability problems. The distinction between discrete and continuous random variables corresponds to fundamentally different probability structures: discrete variables have point masses with positive probability, while continuous variables have probability density spread over intervals with zero probability at individual points. In engineering applications, discrete random variables model counts (number of failures, packet arrivals, defective items), while continuous random variables model measurements (voltage noise, temperature fluctuations, component lifetimes). The study of random variables develops essential skills in probabilistic modeling, computing distributions from physical principles, and using probability functions to make predictions. Mastery of random variables provides the foundation for statistical inference, stochastic processes, queueing theory, and reliability engineering.",
        "The fundamental probability functions—PMF for discrete and PDF for continuous random variables—completely characterize the probability distribution. For discrete $X$, the PMF $p(x) = P(X = x)$ gives probability of each value, with constraints $p(x) \\geq 0$ and $\\sum_x p(x) = 1$. For continuous $X$, the PDF $f(x)$ satisfies $f(x) \\geq 0$ and $\\int_{-\\infty}^{\\infty} f(x)\\,dx = 1$, with $P(a \\leq X \\leq b) = \\int_a^b f(x)\\,dx$. Critically, for continuous variables, $P(X = x) = 0$ for any specific $x$—probability concentrates in intervals, not points. The CDF $F(x) = P(X \\leq x)$ unifies both types: for discrete, $F(x) = \\sum_{t \\leq x} p(t)$; for continuous, $F(x) = \\int_{-\\infty}^x f(t)\\,dt$. The CDF is always well-defined, non-decreasing, and right-continuous. Expected value $E[X]$ quantifies the long-run average: $E[X] = \\sum x \\cdot p(x)$ for discrete or $E[X] = \\int x \\cdot f(x)\\,dx$ for continuous. Linearity of expectation states $E[aX + b] = aE[X] + b$ and $E[X + Y] = E[X] + E[Y]$ even for dependent variables. Variance $\\text{Var}(X) = E[(X - \\mu)^2] = E[X^2] - [E[X]]^2$ measures spread around the mean.",
        "Mastery of random variables is critically important because they form the mathematical foundation for all statistical modeling and analysis in engineering. In reliability engineering, component lifetime is modeled as a continuous random variable with exponential or Weibull distribution. In communications, noise is modeled as a Gaussian random variable affecting signal fidelity. In quality control, the number of defects follows a discrete distribution (Poisson or binomial). Expected value provides the basis for decision-making under uncertainty: expected profit, expected cost, expected system lifetime. Variance and standard deviation quantify risk and variability, essential for tolerance analysis and process control. The ability to derive probability functions from physical principles—constructing PMF from counting arguments or PDF from symmetry or limiting behavior—enables engineers to build custom models for specific applications. Transformations of random variables enable computing distributions of derived quantities: if $Y = g(X)$, finding the distribution of $Y$ requires techniques like the transformation method or moment-generating functions. In examinations, proficiency demonstrates command over probability functions, integration and summation techniques, and ability to translate physical scenarios into mathematical random variable models."
    ],
    "mathematical_formulation": [
        {
            "formula": "PMF (discrete): $p(x) = P(X = x)$ with $\\sum_x p(x) = 1$ and $p(x) \\geq 0$",
            "explanation": "Probability mass function assigns probabilities to discrete values."
        },
        {
            "formula": "PDF (continuous): $f(x)$ with $\\int_{-\\infty}^{\\infty} f(x)\\,dx = 1$ and $f(x) \\geq 0$",
            "explanation": "Probability density function; $P(a \\leq X \\leq b) = \\int_a^b f(x)\\,dx$."
        },
        {
            "formula": "CDF: $F(x) = P(X \\leq x)$",
            "explanation": "Cumulative distribution function, non-decreasing and right-continuous."
        },
        {
            "formula": "For discrete: $F(x) = \\sum_{t \\leq x} p(t)$",
            "explanation": "CDF as sum of PMF values up to $x$."
        },
        {
            "formula": "For continuous: $F(x) = \\int_{-\\infty}^x f(t)\\,dt$ and $f(x) = F'(x)$",
            "explanation": "CDF as integral of PDF; PDF is derivative of CDF."
        },
        {
            "formula": "Expected value (discrete): $E[X] = \\sum_x x \\cdot p(x)$",
            "explanation": "Weighted average of values using PMF as weights."
        },
        {
            "formula": "Expected value (continuous): $E[X] = \\int_{-\\infty}^{\\infty} x \\cdot f(x)\\,dx$",
            "explanation": "Integral of $x$ weighted by PDF."
        },
        {
            "formula": "Linearity: $E[aX + b] = aE[X] + b$",
            "explanation": "Expectation is linear operator."
        },
        {
            "formula": "Variance: $\\text{Var}(X) = E[(X - \\mu)^2] = E[X^2] - [E[X]]^2$",
            "explanation": "Measures spread; $\\mu = E[X]$ is the mean."
        }
    ],
    "worked_examples": [
        {
            "difficulty": "Basic",
            "problem": "A fair die is rolled. Let $X$ be the outcome. Find $E[X]$ and $\\text{Var}(X)$.",
            "solution_steps": [
                "**Step 1**: PMF is $p(x) = \\frac{1}{6}$ for $x \\in \\{1, 2, 3, 4, 5, 6\\}$",
                "**Step 2**: Calculate $E[X]$:",
                "$E[X] = \\sum_{x=1}^{6} x \\cdot \\frac{1}{6} = \\frac{1}{6}(1 + 2 + 3 + 4 + 5 + 6) = \\frac{21}{6} = 3.5$",
                "**Step 3**: Calculate $E[X^2]$:",
                "$E[X^2] = \\sum_{x=1}^{6} x^2 \\cdot \\frac{1}{6} = \\frac{1}{6}(1 + 4 + 9 + 16 + 25 + 36) = \\frac{91}{6}$",
                "**Step 4**: Calculate variance:",
                "$\\text{Var}(X) = E[X^2] - [E[X]]^2 = \\frac{91}{6} - (3.5)^2 = \\frac{91}{6} - 12.25 \\approx 2.92$"
            ],
            "final_answer": "$E[X] = 3.5$, $\\text{Var}(X) \\approx 2.92$"
        },
        {
            "difficulty": "Intermediate",
            "problem": "For continuous random variable $X$ with PDF $f(x) = 2x$ for $0 \\leq x \\leq 1$ (and 0 otherwise), find $P(X > 0.5)$ and $E[X]$.",
            "solution_steps": [
                "**Step 1**: Calculate $P(X > 0.5)$:",
                "$P(X > 0.5) = \\int_{0.5}^{1} 2x\\,dx = [x^2]_{0.5}^{1} = 1 - 0.25 = 0.75$",
                "**Step 2**: Calculate $E[X]$:",
                "$E[X] = \\int_0^1 x \\cdot 2x\\,dx = \\int_0^1 2x^2\\,dx$",
                "$= 2\\left[\\frac{x^3}{3}\\right]_0^1 = 2 \\cdot \\frac{1}{3} = \\frac{2}{3}$"
            ],
            "final_answer": "$P(X > 0.5) = 0.75$, $E[X] = \\frac{2}{3}$"
        },
        {
            "difficulty": "Intermediate",
            "problem": "Find the CDF for discrete random variable with PMF: $p(1) = 0.2$, $p(2) = 0.5$, $p(3) = 0.3$.",
            "solution_steps": [
                "**Step 1**: CDF is cumulative sum: $F(x) = P(X \\leq x) = \\sum_{t \\leq x} p(t)$",
                "**Step 2**: Compute for each region:",
                "$F(x) = 0$ for $x < 1$",
                "$F(x) = 0.2$ for $1 \\leq x < 2$",
                "$F(x) = 0.2 + 0.5 = 0.7$ for $2 \\leq x < 3$",
                "$F(x) = 0.2 + 0.5 + 0.3 = 1$ for $x \\geq 3$"
            ],
            "final_answer": "$F(x) = \\begin{cases} 0 & x < 1 \\\\ 0.2 & 1 \\leq x < 2 \\\\ 0.7 & 2 \\leq x < 3 \\\\ 1 & x \\geq 3 \\end{cases}$"
        }
    ],
    "logical_derivation": "To derive the variance formula $\\text{Var}(X) = E[X^2] - [E[X]]^2$, start from the definition: $\\text{Var}(X) = E[(X - \\mu)^2]$ where $\\mu = E[X]$. Expand the square: $E[(X - \\mu)^2] = E[X^2 - 2\\mu X + \\mu^2]$. Apply linearity of expectation: $= E[X^2] - 2\\mu E[X] + \\mu^2$. Since $\\mu = E[X]$, substitute: $= E[X^2] - 2E[X] \\cdot E[X] + [E[X]]^2 = E[X^2] - 2[E[X]]^2 + [E[X]]^2 = E[X^2] - [E[X]]^2$. This computational formula is often easier to use than the definitional form.",
    "applications": [
        "**Reliability Engineering**: Component lifetime as continuous random variable (exponential, Weibull distribution).",
        "**Quality Control**: Number of defects as discrete random variable (Poisson, binomial distribution).",
        "**Communication Systems**: Noise modeled as Gaussian random variable affecting signal.",
        "**Finance**: Stock returns, portfolio values as random variables for risk analysis.",
        "**Manufacturing**: Measurement errors, dimensional variations as normal random variables.",
        "**Queueing Theory**: Arrival counts, service times as random variables in system analysis.",
        "**Statistical Inference**: Sample means, test statistics as random variables for hypothesis testing."
    ],
    "key_takeaways": [
        "Random variable $X: S \\to \\mathbb{R}$ maps outcomes to numbers, enabling mathematical analysis.",
        "Discrete: PMF $p(x) = P(X = x)$ with $\\sum p(x) = 1$; continuous: PDF $f(x)$ with $\\int f(x)\\,dx = 1$.",
        "For continuous variables, $P(X = x) = 0$ for any specific $x$; probability concentrates in intervals.",
        "CDF $F(x) = P(X \\leq x)$ is universal for both types, non-decreasing, with limits 0 and 1.",
        "Expected value $E[X]$ is long-run average: $\\sum x \\cdot p(x)$ or $\\int x \\cdot f(x)\\,dx$.",
        "Linearity: $E[aX + b] = aE[X] + b$ and $E[X + Y] = E[X] + E[Y]$ (even if dependent).",
        "Variance $\\text{Var}(X) = E[X^2] - [E[X]]^2$ measures spread; standard deviation $\\sigma = \\sqrt{\\text{Var}(X)}$."
    ],
    "common_mistakes": [
        {
            "mistake": "Confusing PMF and PDF: using $P(X = x)$ for continuous variables",
            "why_it_occurs": "Students don't recognize that for continuous random variables, $P(X = x) = 0$.",
            "how_to_avoid": "For continuous: use intervals $P(a \\leq X \\leq b) = \\int_a^b f(x)\\,dx$. Point probabilities are zero."
        },
        {
            "mistake": "Forgetting to verify $\\sum p(x) = 1$ or $\\int f(x)\\,dx = 1$",
            "why_it_occurs": "Students don't check normalization condition.",
            "how_to_avoid": "Always verify PMF sums to 1 or PDF integrates to 1 before using it."
        },
        {
            "mistake": "Computing $E[X^2]$ as $[E[X]]^2$",
            "why_it_occurs": "Students think expectation distributes over squaring.",
            "how_to_avoid": "$E[X^2] \\neq [E[X]]^2$ in general. Compute $E[X^2] = \\sum x^2 p(x)$ or $\\int x^2 f(x)\\,dx$ separately."
        },
        {
            "mistake": "Using PMF formula for PDF calculations",
            "why_it_occurs": "Students apply discrete formulas to continuous variables.",
            "how_to_avoid": "Discrete uses sums $\\sum$; continuous uses integrals $\\int$. Check variable type first."
        },
        {
            "mistake": "Confusing CDF $F(x)$ with PDF $f(x)$",
            "why_it_occurs": "Students mix up notation and relationships.",
            "how_to_avoid": "CDF $F(x) = P(X \\leq x)$ is cumulative; PDF $f(x) = F'(x)$ is derivative. For discrete, $F(x) = \\sum_{t \\leq x} p(t)$."
        },
        {
            "mistake": "Thinking $\\text{Var}(aX + b) = a \\cdot \\text{Var}(X) + b$",
            "why_it_occurs": "Students incorrectly apply linearity to variance.",
            "how_to_avoid": "Variance: $\\text{Var}(aX + b) = a^2 \\text{Var}(X)$ (constant $b$ disappears, $a$ is squared). Only expectation is linear."
        },
        {
            "mistake": "Not accounting for support (range) of random variable",
            "why_it_occurs": "Students integrate or sum over wrong limits.",
            "how_to_avoid": "Identify support (values where $p(x) > 0$ or $f(x) > 0$) and integrate/sum only over that range."
        }
    ],
    "quiz": [
        {
            "question": "Which describes a discrete random variable?",
            "options": [
                "Number of heads in 5 coin flips",
                "Height of a randomly selected person",
                "Time until a light bulb fails",
                "Temperature at noon tomorrow"
            ],
            "correct_answer": 0,
            "explanation": "Number of heads is countable (0, 1, 2, 3, 4, 5), making it discrete. The others are continuous measurements."
        },
        {
            "question": "For continuous random variable $X$ with PDF $f(x)$, $P(X = 5) =$",
            "options": [
                "$0$",
                "$f(5)$",
                "$F(5)$",
                "$\\int_0^5 f(x)\\,dx$"
            ],
            "correct_answer": 0,
            "explanation": "For continuous variables, probability at any single point is zero: $P(X = x) = 0$."
        },
        {
            "question": "If PMF is $p(1) = 0.3$, $p(2) = 0.5$, $p(3) = 0.2$, find $E[X]$:",
            "options": [
                "$1.9$",
                "$2$",
                "$1.5$",
                "$3$"
            ],
            "correct_answer": 0,
            "explanation": "$E[X] = 1(0.3) + 2(0.5) + 3(0.2) = 0.3 + 1.0 + 0.6 = 1.9$."
        },
        {
            "question": "For PDF $f(x) = \\frac{1}{2}$ on $[0, 2]$, find $P(0.5 \\leq X \\leq 1.5)$:",
            "options": [
                "$ 0.5$",
                "$0.25$",
                "$0.75$",
                "$1$"
            ],
            "correct_answer": 0,
            "explanation": "$P(0.5 \\leq X \\leq 1.5) = \\int_{0.5}^{1.5} \\frac{1}{2}\\,dx = \\frac{1}{2}(1.5 - 0.5) = 0.5$."
        },
        {
            "question": "If $E[X] = 5$ and $E[X^2] = 30$, find $\\text{Var}(X)$:",
            "options": [
                "$5$",
                "$25$",
                "$30$",
                "$35$"
            ],
            "correct_answer": 0,
            "explanation": "$\\text{Var}(X) = E[X^2] - [E[X]]^2 = 30 - 25 = 5$."
        },
        {
            "question": "The CDF $F(x) = P(X \\leq x)$ must satisfy:",
            "options": [
                "$\\lim_{x \\to \\infty} F(x) = 1$",
                "$F(x)$ is strictly increasing",
                "$F(x) < 0$ is possible",
                "$F(x) = f(x)$"
            ],
            "correct_answer": 0,
            "explanation": "CDF approaches 1 as $x \\to \\infty$ (eventually includes all probability). It's non-decreasing (not strictly), non-negative, and $F(x) \\neq f(x)$."
        },
        {
            "question": "If $E[X] = 10$, find $E[3X + 5]$:",
            "options": [
                "$35$",
                "$30$",
                "$15$",
                "$45$"
            ],
            "correct_answer": 0,
            "explanation": "Linearity: $E[3X + 5] = 3E[X] + 5 = 3(10) + 5 = 35$."
        },
        {
            "question": "For discrete random variable, the CDF $F(x)$ is:",
            "options": [
                "A step function",
                "Continuous everywhere",
                "Equal to the PMF",
                "Always differentiable"
            ],
            "correct_answer": 0,
            "explanation": "For discrete variables, CDF is a step function with jumps at values where PMF is positive."
        },
        {
            "question": "If $\\text{Var}(X) = 16$, find $\\text{Var}(2X + 3)$:",
            "options": [
                "$64$",
                "$32$",
                "$35$",
                "$16$"
            ],
            "correct_answer": 0,
            "explanation": "$\\text{Var}(aX + b) = a^2 \\text{Var}(X)$, so $\\text{Var}(2X + 3) = 2^2 \\cdot 16 = 64$. Constant doesn't affect variance."
        },
        {
            "question": "The relationship between PDF $f(x)$ and CDF $F(x)$ for continuous variables is:",
            "options": [
                "$f(x) = F'(x)$ and $F(x) = \\int_{-\\infty}^x f(t)\\,dt$",
                "$F(x) = f'(x)$",
                "$f(x) = F(x)$",
                "$F(x) = \\sum f(x)$"
            ],
            "correct_answer": 0,
            "explanation": "PDF is derivative of CDF: $f(x) = \\frac{dF}{dx}$. CDF is integral of PDF: $F(x) = \\int_{-\\infty}^x f(t)\\,dt$."
        },
        {
            "question": "A valid PMF must satisfy:",
            "options": [
                "$\\sum_x p(x) = 1$ and $p(x) \\geq 0$ for all $x$",
                "$\\int p(x)\\,dx = 1$",
                "$p(x) \\leq 1$ only",
                "$p(x) > 0$ for all $x$"
            ],
            "correct_answer": 0,
            "explanation": "PMF must be non-negative and sum to 1 over all possible values."
        },
        {
            "question": "For random variable $X$ with $E[X] = \\mu$, $E[X - \\mu] =$",
            "options": [
                "$0$",
                "$\\mu$",
                "$\\mu^2$",
                "$\\text{Var}(X)$"
            ],
            "correct_answer": 0,
            "explanation": "$E[X - \\mu] = E[X] - \\mu = \\mu - \\mu = 0$. Deviations from mean average to zero."
        }
    ],
    "ai_summary": {
        "key_ideas": [
            "Random variable $X: S \\to \\mathbb{R}$ maps outcomes to numbers, enabling mathematical probability analysis.",
            "Discrete: PMF $p(x) = P(X = x)$ with $\\sum p(x) = 1$. Continuous: PDF $f(x)$ with $\\int f(x)\\,dx = 1$.",
            "For continuous variables, $P(X = x) = 0$ for any specific point; use intervals $P(a \\leq X \\leq b) = \\int_a^b f(x)\\,dx$.",
            "CDF $F(x) = P(X \\leq x)$ is universal: $F(x) = \\sum_{t \\leq x} p(t)$ (discrete) or $F(x) = \\int_{-\\infty}^x f(t)\\,dt$ (continuous).",
            "For continuous: $f(x) = F'(x)$ (PDF is derivative of CDF).",
            "Expected value: $E[X] = \\sum x \\cdot p(x)$ or $\\int x \\cdot f(x)\\,dx$ measures long-run average.",
            "Linearity: $E[aX + b] = aE[X] + b$ and $E[X + Y] = E[X] + E[Y]$ (holds even for dependent variables).",
            "Variance: $\\text{Var}(X) = E[X^2] - [E[X]]^2$ measures spread around mean.",
            "Variance property: $\\text{Var}(aX + b) = a^2 \\text{Var}(X)$ (constant drops out, coefficient squared).",
            "Standard deviation $\\sigma = \\sqrt{\\text{Var}(X)}$ has same units as $X$."
        ],
        "important_formulas": [
            "PMF: $p(x) = P(X = x)$ with $\\sum p(x) = 1$",
            "PDF: $f(x)$ with $\\int f(x)\\,dx = 1$, $P(a \\leq X \\leq b) = \\int_a^b f(x)\\,dx$",
            "CDF: $F(x) = P(X \\leq x)$",
            "$E[X] = \\sum x \\cdot p(x)$ or $\\int x \\cdot f(x)\\,dx$",
            "$\\text{Var}(X) = E[X^2] - [E[X]]^2$",
            "$E[aX + b] = aE[X] + b$, $\\text{Var}(aX + b) = a^2 \\text{Var}(X)$"
        ],
        "common_exam_traps": [
            "Using $P(X = x)$ for continuous variables—it's always zero; use intervals instead.",
            "Thinking $E[X^2] = [E[X]]^2$—compute separately using $\\sum x^2 p(x)$ or $\\int x^2 f(x)\\,dx$.",
            "Applying discrete formulas (sums) to continuous variables or vice versa—check variable type first.",
            "Confusing variance linearity with expectation: $\\text{Var}(aX + b) = a^2 \\text{Var}(X)$, not $a \\cdot \\text{Var}(X) + b$.",
            "Forgetting normalization: PMF must sum to 1, PDF must integrate to 1."
        ],
        "exam_tip": "For continuous variables, always use integrals and intervals. For variance calculations, use $\\text{Var}(X) = E[X^2] - [E[X]]^2$ computational formula. Remember $E$ is linear but variance is quadratic in scaling."
    }
}